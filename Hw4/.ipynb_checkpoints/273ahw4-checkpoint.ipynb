{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.matrix([[0,0,1,1,0,-1],[1,1,0,1,0,-1],[0,1,1,1,1,-1],\n",
    "               [1,1,1,1,0,-1],[0,1,0,0,0,-1],[1,0,1,1,1, 1],\n",
    "               [0,0,1,0,0, 1],[1,0,0,0,0, 1],[1,0,1,1,0, 1],\n",
    "               [1,1,1,1,1,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(value):\n",
    "    p1 = np.mean(value>0)\n",
    "    p2 = 1-p1\n",
    "    if p1 ==0:\n",
    "        entropy = p2*np.log2(1/p2)\n",
    "    elif p2==0 :\n",
    "        entropy = p1*np.log2(1/p1)\n",
    "    else:\n",
    "        entropy = p1*np.log2(1/p1)+p2*np.log2(1/p2)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of class variable is 0.970951\n"
     ]
    }
   ],
   "source": [
    "Hy = calculate_entropy(X[:,-1])\n",
    "print('Entropy of class variable is %0.6f' % Hy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_info_gain(feature_index,X,entropy_class,feaure_lst):\n",
    "    ture_pos = X[:,-1][X[:,feature_index-1]>0]\n",
    "    entropy_pos = calculate_entropy(ture_pos)\n",
    "    false_pos = X[:,-1][X[:,feature_index-1]<1]\n",
    "    entropy_false = calculate_entropy(false_pos)\n",
    "    p1 = np.mean(X[:,feature_index-1]>0)\n",
    "    p2 = 1-p1 \n",
    "    info_gain = p1*(entropy_class-entropy_pos)+p2*(entropy_class-entropy_false)\n",
    "    print('information gain for feature {} {} is {} \\n'.format(feature_index,feaure_lst[feature_index-1],info_gain))\n",
    "    print('      entropy true  is: {} \\n      entropy false is: {} \\n'.format((entropy_pos),(entropy_false)))\n",
    "    return info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information gain for feature 1 know author is 0.04643934467101556 \n",
      "\n",
      "      entropy true  is: 1.0 \n",
      "      entropy false is: 0.8112781244591328 \n",
      "\n",
      "information gain for feature 2 is long is 0.6099865470109875 \n",
      "\n",
      "      entropy true  is: 0.0 \n",
      "      entropy false is: 0.7219280948873623 \n",
      "\n",
      "information gain for feature 3 has research is 0.005802149014345906 \n",
      "\n",
      "      entropy true  is: 0.9852281360342514 \n",
      "      entropy false is: 0.9182958340544893 \n",
      "\n",
      "information gain for feature 4 has grade is 0.0912774462416802 \n",
      "\n",
      "      entropy true  is: 0.8631205685666309 \n",
      "      entropy false is: 0.9182958340544896 \n",
      "\n",
      "information gain for feature 5 has lottery is 0.0058021490143459024 \n",
      "\n",
      "      entropy true  is: 0.9182958340544893 \n",
      "      entropy false is: 0.9852281360342514 \n",
      "\n",
      "largest info index is 2\n"
     ]
    }
   ],
   "source": [
    "feaure_lst = ['know author','is long','has research',\n",
    "             'has grade','has lottery']\n",
    "largest_info_index = 0\n",
    "H = 0\n",
    "for i in range(1,6):\n",
    "    H_new = calculate_info_gain(i,X,Hy,feaure_lst);\n",
    "    if H_new > H:\n",
    "        H = H_new\n",
    "        largest_info_index = i\n",
    "print('largest info index is {}'.format(largest_info_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should split feature 2 first, if email is long predict not read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0,  0,  1,  1,  0, -1],\n",
       "        [ 1,  0,  1,  1,  1,  1],\n",
       "        [ 0,  0,  1,  0,  0,  1],\n",
       "        [ 1,  0,  0,  0,  0,  1],\n",
       "        [ 1,  0,  1,  1,  0,  1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.matrix([[0,0,1,1,0,-1],[1,1,0,1,0,-1],[0,1,1,1,1,-1],\n",
    "               [1,1,1,1,0,-1],[0,1,0,0,0,-1],[1,0,1,1,1, 1],\n",
    "               [0,0,1,0,0, 1],[1,0,0,0,0, 1],[1,0,1,1,0, 1],\n",
    "               [1,1,1,1,1,-1]])\n",
    "X_new = np.delete(X,[1,2,3,4,9],0)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information gain for new feature 1 know author is 0.5709505944546687 \n",
      "\n",
      "      entropy true  is: 0.0 \n",
      "      entropy false is: 1.0 \n",
      "\n",
      "information gain for new feature 2 has research is 0.24902249956730638 \n",
      "\n",
      "      entropy true  is: 0 \n",
      "      entropy false is: 0.7219280948873623 \n",
      "\n",
      "information gain for new feature 3 has grade is 0.3219280948873624 \n",
      "\n",
      "      entropy true  is: 0.8112781244591328 \n",
      "      entropy false is: 0.0 \n",
      "\n",
      "information gain for new feature 4 has lottery is 0.41997309402197497 \n",
      "\n",
      "      entropy true  is: 0.9182958340544896 \n",
      "      entropy false is: 0.0 \n",
      "\n",
      "largest info index is new/old feature 1\n"
     ]
    }
   ],
   "source": [
    "def calculate_info_gain(feature_index,X,entropy_class,feaure_lst):\n",
    "    ture_pos = X[:,-1][X[:,feature_index-1]>0]\n",
    "    if ture_pos.size == 0:\n",
    "        entropy_pos = 0\n",
    "    else:\n",
    "        entropy_pos = calculate_entropy(ture_pos)\n",
    "    false_pos = X[:,-1][X[:,feature_index-1]<1]\n",
    "    if false_pos.size ==0:\n",
    "        entropy_false = 0\n",
    "    else:\n",
    "        entropy_false = calculate_entropy(false_pos)\n",
    "    p1 = np.mean(X[:,feature_index-1]>0)\n",
    "    p2 = 1-p1 \n",
    "    info_gain = p1*(entropy_class-entropy_pos)+p2*(entropy_class-entropy_false)\n",
    "    print('information gain for new feature {} {} is {} \\n'.format(feature_index,feaure_lst[feature_index-1],info_gain))\n",
    "    print('      entropy true  is: {} \\n      entropy false is: {} \\n'.format((entropy_pos),(entropy_false)))\n",
    "    return info_gain\n",
    "\n",
    "feaure_lst = ['know author','has research',\n",
    "             'has grade','has lottery']\n",
    "largest_info_index = 0\n",
    "Hy = calculate_entropy(X[[0,5,3,7,8],-1])\n",
    "H = 0\n",
    "for i in range(1,5):\n",
    "    H_new = calculate_info_gain(i,X_new,Hy,feaure_lst);\n",
    "    if H_new > H:\n",
    "        H = H_new\n",
    "        largest_info_index = i\n",
    "print('largest info index is new/old feature {}'.format(largest_info_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1,  1,  0, -1],\n",
       "        [ 1,  0,  0,  1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_new = np.delete(X_new,[1,3,4],0)\n",
    "X_new_new = np.delete(X_new_new,[0,1],1)\n",
    "X_new_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Complete Desicion Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "if X2( is long?) is True:\n",
    "    predict Not Read (since entropy is zero)\n",
    "elif X2 is False:\n",
    "    if X1(know author?) is True: \n",
    "        predict Read \n",
    "    elif X1 is False: # (note that we only have two raws now as X_new_new shows)\n",
    "        if X4 (has grade) is True:\n",
    "            predict not read\n",
    "        elif X4  (has grade) is False:\n",
    "            predict read\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltools as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('data/X_train.txt',delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt',delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature 1 minimum  is 197.0\n",
      "feature 1 maximum  is 253.0\n",
      "feature 1 mean     is 241.89897349999998\n",
      "feature 1 variance is 81.19881598129776\n",
      "\n",
      "feature 2 minimum  is 190.0\n",
      "feature 2 maximum  is 248.0\n",
      "feature 2 mean     is 228.38130700000002\n",
      "feature 2 variance is 89.15026534175098\n",
      "\n",
      "feature 3 minimum  is 214.97\n",
      "feature 3 maximum  is 252.02\n",
      "feature 3 mean     is 241.90593450000003\n",
      "feature 3 variance is 34.55774434670975\n",
      "\n",
      "feature 4 minimum  is 205.42\n",
      "feature 4 maximum  is 252.02\n",
      "feature 4 mean     is 233.8253765\n",
      "feature 4 variance is 94.50721140824776\n",
      "\n",
      "feature 5 minimum  is 10.0\n",
      "feature 5 maximum  is 17130.0\n",
      "feature 5 mean     is 2849.0465\n",
      "feature 5 variance is 10505588.30063775\n",
      "\n",
      "feature 6 minimum  is 0.0\n",
      "feature 6 maximum  is 12338.0\n",
      "feature 6 mean     is 862.8611\n",
      "feature 6 variance is 3090415.2075067903\n",
      "\n",
      "feature 7 minimum  is 0.0\n",
      "feature 7 maximum  is 9238.0\n",
      "feature 7 mean     is 163.65265\n",
      "feature 7 variance is 698073.3556979776\n",
      "\n",
      "feature 8 minimum  is 0.0\n",
      "feature 8 maximum  is 27.419\n",
      "feature 8 mean     is 3.0557549345\n",
      "feature 8 variance is 7.276890946708305\n",
      "\n",
      "feature 9 minimum  is 1.2189\n",
      "feature 9 maximum  is 18.107\n",
      "feature 9 mean     is 6.311441945\n",
      "feature 9 variance is 6.183003202965117\n",
      "\n",
      "feature 10 minimum  is 0.0\n",
      "feature 10 maximum  is 11.368\n",
      "feature 10 mean     is 1.89391480435\n",
      "feature 10 variance is 4.150931810214395\n",
      "\n",
      "feature 11 minimum  is 0.0\n",
      "feature 11 maximum  is 18.771\n",
      "feature 11 mean     is 4.289551351\n",
      "feature 11 variance is 3.944615292538295\n",
      "\n",
      "feature 12 minimum  is 0.0\n",
      "feature 12 maximum  is 14.745\n",
      "feature 12 mean     is 2.7977508345000004\n",
      "feature 12 variance is 1.9323439727669185\n",
      "\n",
      "feature 13 minimum  is 1.0271\n",
      "feature 13 maximum  is 278.71\n",
      "feature 13 mean     is 10.452536635\n",
      "feature 13 variance is 170.00184292005338\n",
      "\n",
      "feature 14 minimum  is -999.9\n",
      "feature 14 maximum  is 769.2\n",
      "feature 14 mean     is 7.65813\n",
      "feature 14 variance is 1528.9473589031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    print(\"feature {} minimum  is {}\".format(i+1,np.min(X[:,i])))\n",
    "    print(\"feature {} maximum  is {}\".format(i+1,np.max(X[:,i])))\n",
    "    print(\"feature {} mean     is {}\".format(i+1,np.mean(X[:,i])))\n",
    "    print(\"feature {} variance is {}\\n\".format(i+1,np.var(X[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature index</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>197.0000</td>\n",
       "      <td>253.000</td>\n",
       "      <td>241.898974</td>\n",
       "      <td>8.119882e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>190.0000</td>\n",
       "      <td>248.000</td>\n",
       "      <td>228.381307</td>\n",
       "      <td>8.915027e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>214.9700</td>\n",
       "      <td>252.020</td>\n",
       "      <td>241.905935</td>\n",
       "      <td>3.455774e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>205.4200</td>\n",
       "      <td>252.020</td>\n",
       "      <td>233.825376</td>\n",
       "      <td>9.450721e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>17130.000</td>\n",
       "      <td>2849.046500</td>\n",
       "      <td>1.050559e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12338.000</td>\n",
       "      <td>862.861100</td>\n",
       "      <td>3.090415e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9238.000</td>\n",
       "      <td>163.652650</td>\n",
       "      <td>6.980734e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>27.419</td>\n",
       "      <td>3.055755</td>\n",
       "      <td>7.276891e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.2189</td>\n",
       "      <td>18.107</td>\n",
       "      <td>6.311442</td>\n",
       "      <td>6.183003e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.368</td>\n",
       "      <td>1.893915</td>\n",
       "      <td>4.150932e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.771</td>\n",
       "      <td>4.289551</td>\n",
       "      <td>3.944615e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14.745</td>\n",
       "      <td>2.797751</td>\n",
       "      <td>1.932344e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0271</td>\n",
       "      <td>278.710</td>\n",
       "      <td>10.452537</td>\n",
       "      <td>1.700018e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>-999.9000</td>\n",
       "      <td>769.200</td>\n",
       "      <td>7.658130</td>\n",
       "      <td>1.528947e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature index   minimum    maximum         mean           var\n",
       "0               1  197.0000    253.000   241.898974  8.119882e+01\n",
       "1               2  190.0000    248.000   228.381307  8.915027e+01\n",
       "2               3  214.9700    252.020   241.905935  3.455774e+01\n",
       "3               4  205.4200    252.020   233.825376  9.450721e+01\n",
       "4               5   10.0000  17130.000  2849.046500  1.050559e+07\n",
       "5               6    0.0000  12338.000   862.861100  3.090415e+06\n",
       "6               7    0.0000   9238.000   163.652650  6.980734e+05\n",
       "7               8    0.0000     27.419     3.055755  7.276891e+00\n",
       "8               9    1.2189     18.107     6.311442  6.183003e+00\n",
       "9              10    0.0000     11.368     1.893915  4.150932e+00\n",
       "10             11    0.0000     18.771     4.289551  3.944615e+00\n",
       "11             12    0.0000     14.745     2.797751  1.932344e+00\n",
       "12             13    1.0271    278.710    10.452537  1.700018e+02\n",
       "13             14 -999.9000    769.200     7.658130  1.528947e+03"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "new_dataframe = pd.DataFrame(\n",
    "    {\n",
    "        \"feature index\" :range(1,15),\n",
    "        \"minimum\":np.min(X,0),\n",
    "        \"maximum\":np.max(X,0),\n",
    "        \"mean\":np.mean(X,0),\n",
    "        \"var\": np.var(X,0)  \n",
    "    }\n",
    ")\n",
    "new_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = X[:10000] # shuffled\n",
    "Ytr = Y[:10000]\n",
    "Xva = X[10000:20000]\n",
    "Yva = Y[10000:20000]\n",
    "learner = ml.dtree.treeClassify(Xtr,Ytr,maxDepth=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   error is:  0.0108\n",
      "Validation error is:  0.3774\n"
     ]
    }
   ],
   "source": [
    "print('Training   error is:  {}'.format(learner.err(Xtr,Ytr)))\n",
    "print('Validation error is:  {}'.format(learner.err(Xva,Yva)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
